---
title: "Predicting Which States are Most Interested in the term *China Virus* Based off Identity Politics, Demography and COVID-19 Statistics "
author: "Federico Chung, Will Madairy, Sofia Pozsonyiova, Quinn Rafferty"
date: 'May 8,2020'
output:
  html_document:
    toc: true
    toc_float: true
---

```{r, warning=FALSE, include=FALSE, message=FALSE}
library(dplyr)
library(ggrepel)
library(usmap)
library(maps)
library(ggplot2)
library(tidyverse)
library(ggmap)
library(viridis)
library(rgdal)
library(gridExtra)
library(plotly)
library(janitor)
library(reshape2)
library(tidyr)
library(rstan)
library(rstanarm)
library(bayesplot)
library(sf)
library(remotes)
```

```{r, include=FALSE, warning=FALSE}
prediction_summary_data <- function(y, yrep, prob_inner = 0.5, prob_outer = 0.95){
  # Calculate summary statistics of simulated 
  # posterior predictive models for each case
  l_outer <- function(x){quantile(x, (1-prob_outer) / 2)}
  l_inner <- function(x){quantile(x, (1-prob_inner) / 2)}
  u_inner <- function(x){quantile(x, 1 - (1-prob_inner) / 2)}
  u_outer <- function(x){quantile(x, 1 - (1-prob_outer) / 2)}
  df <- data.frame(yrep) %>% 
    summarize_all(list(mean, sd, median, mad, l_outer, l_inner, u_inner, u_outer)) %>%
    unlist() %>% 
    matrix(., length(y), 8) %>% 
    data.frame()
  names(df) <- c("post_mean", "post_sd", "post_median", "post_mad", "l_outer", "l_inner", "u_inner", "u_outer")
  data.frame(cbind(y, df))
}


prediction_summary <- function(y, yrep, prob_inner = 0.5, prob_outer = 0.95){
  # This function summarizes the predictions across all cases
  pred_data <- prediction_summary_data(y, yrep, prob_inner = prob_inner, prob_outer = prob_outer) %>% 
    mutate(error = y - post_median) %>% 
    mutate(error_scaled = error / post_mad) %>% 
    mutate(within_inner = (y >= l_inner) & (y <= u_inner)) %>% 
    mutate(within_outer = (y >= l_outer) & (y <= u_outer))
  
  
  pred_summary <- pred_data %>% 
    summarize(mae = median(abs(error)), 
      mae_scaled = median(abs(error_scaled)),
      within_inner = mean(within_inner),
      within_outer = mean(within_outer)
    )
  names(pred_summary)[3] <- paste0("within_", prob_inner*100)
  names(pred_summary)[4] <- paste0("within_", prob_outer*100)
  
  pred_summary
}
```


# 1. Introduction

On March 17, 2020 President Trump referred to the Coronavirus as the "China Virus." Shortly after, there was an uptick in verbal and physical attacks against Asian-Americans. One aspect of public health that is often thrown to the wayside is how influential public officials and leaders are in disseminating public health information. Moreover, not only can their words change the public's views on a health matter but it can also shift a nation's perspective on someone's identity. The Asian Pacific Policy and Planning Council reported that in their first four weeks of receiving reports on COVID-19 anti-Asian discirimnation, they recieved more than 1,500 incidents [CITE]. This abrupt spasm of racism mimics the kind faced by American Muslims, Arabs and South Asians in the United States after the terrorist attacks of 9/11. However, when President George W. Bush urged tolerance of American Muslims, this time President Trump is using language that Asian-Americans say is inciting racist attacks.

In addition, given the influence of identity politics we may expect the term "China Virus" to be more polarizing to certain identities and states.The Pew Reserach Center discovered that nearly three-quarters of Repbulicans and Republican-leaning indepdents view China unfavoriably[CITE]. But the majority of reports to the AAPI were from Democrat leaning states like California, Washington and Illinois [CITE]. Moreover, states that have a higher number of reported positive cases tend to have a higher interest in Googling the term "China Virus" [CITE].  Thus, this begs the question: What factors of the poltiical, demographic and COVID-19 spheres best predicts the level of interest a state will have in the term "China Virus?" 

In order to answer this question, we utilized Monte Carlo Markov Chains to build four predictive models that included some of the variables mentioned above. Model 1 is our simplest model while Model 4 is our most complex model. We then ran several different diagnostic tests such as MCMC and PP checks to evaluate the quality and structures of our models. While all the models had some different levels of predictive strength, our best model was ___________. This model proved to provide the best balance between complexity and quality. 

\



# 2. Data
```{r, message=FALSE, include=FALSE}

Finaldata<-read_csv("time_series_final_Data.csv")
google<-read.csv("Google/googlefinal.csv")

Finaldata <- Finaldata %>% mutate(Day= as.Date(Day, tryFormats = "%m/%d/%Y"))

day_initial<- as.Date("03/14/2020",tryFormats = "%m/%d/%Y")
day_final<- as.Date("03/21/2020",tryFormats = "%m/%d/%Y")


Finaldata<- Finaldata%>%
  filter(Day>=day_initial)%>%
  filter(Day<=day_final)

```

## 2.1 Data Descriptions

## 2.2 Variables of interest

## 2.3 Visualizations _NEED TO WEAVE A COHEASIVE MESSAGE BETWEEN THESE VISUALIZATIONS TO TELL A STORY _

### 2.3a Demographic 

```{r, echo=FALSE, warning=FALSE, fig.align=center}
Finaldata$hover <- with(Finaldata, paste(polyname, "<br>","Positive Cases:", positive, "<br>","Negative Cases:", negative,"<br>",
                           "Total Cases:", totalTestResults,"<br>", "% White:", percent_white,"<br>",
                            "% Asian:", percent_asian, "<br>", "State Color:", StateColor,
                        "<br>", "Total Population", total_population))
# give state boundaries a white border
l <- list(color = toRGB("white"), width = 2)
# specify some map projection/options
g <- list(
  scope = 'usa',
  projection = list(type = 'albers usa'),
  showlakes = TRUE,
  lakecolor = toRGB('white')
)

fig <- plot_geo(Finaldata, locationmode = 'USA-states')
fig <- fig %>% add_trace(
    z = ~ChinaVirusInterest, text = ~hover, locations = ~State,
    color = ~ChinaVirusInterest, colors = 'Oranges'
  )
fig <- fig %>% colorbar(title = "Interest")
fig <- fig %>% layout(
    title = '2020 Google Search Interest of "China Virus" by State <br>(Hover for additional information)', geo=g
  )

#########white fig
whitefig <- plot_geo(Finaldata, locationmode = 'USA-states')
whitefig <- whitefig %>% add_trace(
    z = ~percent_white, locations = ~State,
    color = ~percent_white, colors = 'Blues'
  )
whitefig <- whitefig %>% colorbar(title = "% White")
whitefig <- whitefig %>% layout(
    title = 'Percent White Identifying by State', geo=g
  )

#### Asian fig
asianfig <- plot_geo(Finaldata, locationmode = 'USA-states')
asianfig <- asianfig %>% add_trace(
    z = ~percent_asian, locations = ~State,
    color = ~percent_asian, colors = 'Greens'
  )
asianfig <- asianfig %>% colorbar(title = "% Asian")
asianfig <- asianfig %>% layout(
    title = 'Comparison of Percent Asian and White Identifying by State',geo=g
  )

fig
subplot(whitefig,asianfig)


```



Our first visualization is looking at the percent of residents that identify as white within the United States compared to those whom identify as asian. As you can see, there is a higher percent of white identifying residents overall but most specifically in the Midwest and northeast states. In regards to Asian-Americans, there is practically less than .1% per state with the exception of California and New York. From this visualization we can also see that places like Texas, California, and New Mexico have much lower white identifying residents which could provide important information for us in our actual analysis. 

### 2.3b Google China Virus


During the 2020-03-14 - 2020-03-21 week, Trump in an official press announcement labeled the Corona Virus as "China Virus" and we wanted to see how his comments affected search patterns across states.

```{r, warning=FALSE, message= FALSE, echo=FALSE}

a<-Finaldata %>% 
  #filter(Day<=day2)%>%
  #filter(Day>=day1)%>%
  group_by(Region, Day) %>% 
  summarize(ChinaVirusSearch = median(ChinaVirusInterest)) %>% 
  ggplot(aes(x=Day, y=ChinaVirusSearch, color=Region))+
  geom_point()+ geom_line()

ggplotly(a)
```

This plot shows the relationship of “China Virus” search interest over grouped by region. This plots shows that there are certainly key events that trigger an uptick in searches overall. In this plot it is not clear which region may search China Virus more or less often, but it does show a that the regions move together in search interest, which would imply federal level events like a Donald Trump tweet to trigger these interest spikes. 

```{r, warning=FALSE, message= FALSE, echo=FALSE}
b<- ggplot(Finaldata, aes(x = ChinaVirusInterest, fill = as.factor(State))) + 
  geom_density(alpha = 0.5)+ ggtitle("China Virus Density by State") + labs(fill="State")

ggplotly(b)
```
As we can see from the density plot of the China Virus Interest during our time period 2020-03-14 - 2020-03-21, it behaves relatively normal with a small bump at 0. As a group we believe this bump occurs as 0 is the lowest value it can take and because of that limitation of the China Virus Interest we see a small bump around 0. One could argue against a normal distribution as it kinda looks a bit right skewed. But our team believes that a normal distribution is the best at describing the density.  

We can see that the variability in Google interest in the term China Virus is has quite a large range between states. There are very few states that have high densities among the upper echelons of the interest scale but there are some interesting peaks of densities among the lower values. For example, we can see that Alaska, Wyoming and Iowa have unusual peaks around the 25-50 range. It is is also interesting interesting to note that there isn't an *obvious* mean or median value of China Virus interest among the states. 


### 2.3c COVID-19

```{r, warning=FALSE, message= FALSE, echo=FALSE}
c <-  ggplot(Finaldata, aes(y=positive, x=Winner, fill=(Winner)))+
      geom_boxplot() +
      facet_wrap(~Region)+
      theme(legend.position = "none") +
      scale_fill_manual(values = c("Democrat"="blue3", "Republican"= "red3"))+
      lims(y= c(0,1000))+
      ggtitle("Positive COVID-19 Cases by State Political Party Winner & Region")
ggplotly(c)
```
This visualisation depicts the distribution of positive COVID-19 cases by region and by which political party won in the 2016 elections. We can see that Democrat states in the Midwest, Mountain, and West have a larger range and higher quantile metrics for positive cases overall. For the Northeast and South regions the mean of positive COVID-19 cases are higher but not significantly. This is an interesting pattern considering that poltical party affiliation appears to interact with the number of postive cases by region. 


\
\



# 3. Methods & Models (Feddy and Will)

## Model 1 Repeated Measures Model
 
  For our simplest model we decided to use a repeated measures model. Our team decided that the repeated measures model was necessary component because of how our data is set up. As we can see in our dataset, each state has a value for their `ChinaVirusInterest` for each day in our target period (2020-03-14 - 2020-03-21). Given the ability to use repeated measures and our prior understanding of the varying characteristics (demographic,political,covid-impact) within different states, the repeated measures model allows us to capture these differences in `ChinaVirusInterest` with the $\theta_i$ value which represents each state's mean value.
  


### Model Structure


$$\begin{aligned}
Y_{ij}|\theta_i, \mu, \sigma_w, \sigma_b \sim N(\theta_i,\sigma_w^2)\\
\theta_i|\mu,\sigma_b \overset{ind}{\sim} N(\mu, \sigma_b^2)\\
\sigma_b,\sigma_w \sim Exp(...)
\end{aligned}$$

\
$Y_{ij} =$ `ChinaVirusInterest` per:
\
$i=State$
\
and $j= Day$ 
\
$\theta_i =$ State i's unique mean value
\
$\sigma_w =$ within state variation
\
$\sigma_b =$ between state variation

 We decided that our MCMC model should take in values from a normal distribution because ChinaVirusInterest's distribution is fairly normal. Although the tails are not as flat as we would want them to be, we can decided that a normal distribution was best to model ChinaVirusInterest. 

```{r, message=FALSE, include=FALSE}
model_data<-
  Finaldata%>%
  mutate(Day=as.numeric(Day)-as.numeric(min(Day)))%>%
  select(ChinaVirusInterest, Day, percent_white, StateColor, positive, State)

model_data<- na.omit(model_data)
```





```{r results = "hide", include = FALSE, cache=TRUE}

#Repeated Measures Model
set.seed(454)
RM_model <- stan_glmer(
  ChinaVirusInterest ~ (1 | State),
  data = model_data, family = gaussian,
)
```

## Model2: Normal Regression

For our second model, we decided that we wanted to understand what made some states more responsive to ChinaVirusInterest than others. As you saw in our research motivation section, we wanted to explore what explained the differences in interest for the “China Virus” term. Was it a political difference, a demographic or a covid-impact related difference? To do this we used a simple Normal Regression model with the following specifications. For our demographic specification we used `percent_white`, for our political specification we used `StateColor` and for our Covid-impact specification we used `positive` (#of positive cases). 

### Model Structure
$$\begin{aligned}
Y_{i}|\beta_0, \beta_1, \beta_2,\beta_3,\beta_4 &\overset{ind}{\sim} N(\beta_0+ \beta_1X_1 + \beta_2X_2 + \beta_3X_3+ \beta_4X_4,\sigma^2)\\
\beta_0,\beta_1, \beta_2,\beta_3 &\sim N(...,...)\\
\sigma &\sim Exp(...)\\
\end{aligned}$$


$Y = ChinaVirusInterest\\$
\
$i = state\\$
\
$j = Days\\$
\
$X_{ij} = \text{Days}\\$
\
$X_2 = \text{percent_white}\; X_3 =\text{StateColor}\;   X_4 =\text{Total Test Results}\\$
\
$\sigma = \text{Variance in }$ `ChinaVirusInterest`
\

```{r results = "hide", include = FALSE, cache=TRUE}
#Normal Regression Model
set.seed(454)
NR_model <- stan_glm(
  ChinaVirusInterest ~ Day + percent_white+StateColor+positive,
  data = model_data, family = gaussian,
  chains = 4, iter = 10000, refresh = 0
)
```

## Model 3: Normal Regression + Repeated Measures

For our third model, we decided to combine the first two models to first understand variations in political, demographic, covid-related variables and also be able to capture variation that we could not explain in model 2. Additionally, we kept the correlation structure that we saw in model 1, but we included the variables in model 2 so that we could explain why some states had a larger `ChinaVirusInterest` than others. Similar to model 1, model 3 allows us to capture differences in `ChinaVirusInterest` with the $\theta_i$ value which represents each state's mean value.
### Model Structure

$$\begin{aligned}
Y_{ij}|\theta,\mu,\beta_0, \beta_1, \beta_2,\beta_3,\beta_4,\sigma_w,\sigma_b &\sim N(\theta_i +\beta_1X_1 + \beta_2X_2 + \beta_3X_3+ \beta_4X_4, \sigma_w^2)\\
\theta_i|\mu, \sigma_b &\overset{ind}{\sim}N (\mu, \sigma_b^2)\\
\beta_0,\beta_1, \beta_2,\beta_3 &\sim N(...,...)\\
\sigma_w,\sigma_b &\sim Exp(...)\\
\end{aligned}$$

$Y = ChinaVirusInterest\\$
\
$i = state\\$
\
$j = Days\\$
\
$X_{ij} = \text{Days}\\$
\
$X_2 = \text{percent_white}\; X_3 =\text{StateColor}\;   X_4 =\text{Total Test Results}\\$
\
$\sigma_w = \text{within state variation} \\$
\
$\sigma_b =  \text{between state variation}\\$
\

```{r results = "hide", include = FALSE, cache=TRUE}
set.seed(454)

model_3 <- stan_glmer(
  ChinaVirusInterest ~ Day + StateColor + percent_white + positive + (1 | State), 
  data = model_data, family = gaussian, chains = 4, iter = 5000*2
)
```


## Model 4: Longitudinal Model (state-specific slopes)

Because of the structure of our data, we are also able to create a longitudinal model as we have repeated measures for `ChinaVirusInterest` and corresponding observations for `Day`. In this more complex model we allow for state-specific slopes and intercepts to predict their behavior of `ChinaVirusInterest`. As the Days increase we get closer to when Trump addressed the Corona Virus as "China Virus". Thus if we see increasing slopes we might conclude that in that state, the effect of Trump addressing the Corona Virus as "China Virus" created an increase in the interest of the term and viceversa. 



### Model Structure

$$
\begin{split}
Y_{ij} | b_0, b_1, \beta_0, \beta_1,\beta_2,\beta_3,\beta_4 \sigma_w, \sigma_{0b}, \sigma_{1b} & \sim N( b_{0i} + b_{1i} X_{ij}+ \beta_2X_2 + \beta_3X_3 +\beta_4X_4, \; \sigma_w^2) \\
b_{0i} | \beta_0, \sigma_{0b} & \stackrel{ind}{\sim} N(\beta_0, \sigma_{0b}^2) \\
b_{1i} | \beta_1, \sigma_{1b} & \stackrel{ind}{\sim} N(\beta_1, \sigma_{1b}^2) \\
\beta_0,\beta_1,\beta_2,\beta_3,\beta_4 & \sim N(..., ...) \\
\sigma_w & \sim Exp(...) \\
\sigma_{0b} & \sim Exp(...) \\
\sigma_{1b} & \sim Exp(...) \\
\end{split}
$$
In this hierarchical model each state receives a specific slope and intercept. The first step is determined through determining the $\beta_{0} - \beta_{4}$ values which represent the intercept, slope, and our three demographic interactions that we bring in from model 3. The $\beta_{0}$ represents the intercept value for all states. From this value each state derives its individual $b_{0i}$ which represents that state’s individual intercept value. In the diagram below we see that the $b_{0i}$ values are normally distributed around the $\beta_{0}$ and are distributed by $\sigma_{0b}$. This same process occurs for determining state specific slopes however we use $\beta_{1}$ and $b_{1i}$. 

The main purpose of this model is to find the magnitude of $\sigma_{1b}$ since this deviation is what determines the significance of their truly being state level unique slopes or not, and therefore determines if we need to use this more flexible model to predict `ChinaVirusInterest`. 


\
$Y = ChinaVirusInterest\\$
\
$i = state\\$
\
$j = Days\\$
\
$X_{ij} = \text{Days}\\$
\
$X_2 = \text{percent_white}\; X_3 =\text{StateColor}\;   X_4 =\text{Total Test Results}\\$
\
$\sigma_w = \text{within state variation} \\$
\
$\sigma_{0b} =  \text{between state variation for intercept}\\$
\
$\sigma_{1b} = \text{between state variation for slopes}\\$
\
$X_{ij} = \text{Days}$
\
$b_{0i} = \text{State-Specific-Intercept}$
\
$\beta_0 = \text{Population-wide-Intercept}$
\
$b_{1i} = \text{State-Specific-Slope}$
\
$\beta_1 = \text{Population-wide-Slope}$


```{r results = "hide", include = FALSE, cache=TRUE}
set.seed(454)
complexmod <- stan_glmer(
  ChinaVirusInterest ~ Day + StateColor + percent_white + positive + (Day | State), 
  data = model_data, family = gaussian, chains = 4, iter = 5000*2
)
```



\
\

# 4. Model Evaluation (RESULTS)


## 4.1 Model 1 Evaluation (Repeated measures)

```{r, message=FALSE, include=FALSE}
g1 <- mcmc_dens(RM_model, pars = "sigma") + 
  labs(x = expression(sigma[w])) +
  lims(x=c(5, 25))
g2 <- mcmc_dens(RM_model, 
  pars = "Sigma[State:(Intercept),(Intercept)]", transformations = sqrt) + 
  labs(x = expression(sigma[b])) +
   lims(x=c(5, 25))
grid.arrange(g1,g2,ncol=2)
```

In the output above we see that the within deviation is much narrow than the between deviation. This matches our intuition in the model that utilizing the repeated measures, fixed effects model will be able to explain a greater amount of the variation. 

```{r, message=FALSE, include=FALSE}
# Store the chains
rm_df <- as.array(RM_model) %>% 
  melt %>% 
  pivot_wider(names_from = parameters, values_from = value)

# Wrangle the chains
rm_df <- rm_df %>% 
  mutate(sigma_sq_w = sigma^2, sigma_sq_b = `Sigma[State:(Intercept),(Intercept)]`) %>% 
  mutate(correlation = sigma_sq_b / (sigma_sq_b + sigma_sq_w))

ggplot(rm_df, aes(x = correlation)) + 
    geom_density()
```

This correlation table shows us that there is relatively weak correlation within each given daily observation within a state. Although there is not a strong correlation, it is correct for us to utilize a repeated measuress model in order to account for the correlation within states. 

##mcmc_ stable
```{r}
mcmc_trace(RM_model)
mcmc_dens_overlay(RM_model) 
```



##ppcheck

```{r}
pp_check(RM_model)
```


## 4.2 Model 2 Evaluation (Normal Regression)

##mcmc_ stable

```{r}
mcmc_trace(NR_model)
mcmc_dens_overlay(NR_model) 
```
##ppcheck


## 4.3 Model 3 Evaluation(Repeated Reg + Normal)

##mcmc_ stable

```{r}
mcmc_trace(model_3)
mcmc_dens_overlay(model_3) 
```

##ppcheck
```{r}
pp_check(model_3)
```

## 4.4 Model 4 Evaluation (Longitudinal)

##mcmc_ stable

```{r}
mcmc_trace(complexmod)
mcmc_dens_overlay(complexmod) 
```

##ppcheck

```{r}
pp_check(complexmod)
```

## Are our models strong?: Prediction & classification summaries

```{r}
#Repeated Measures
set.seed(454)
pred_1 <- posterior_predict(
  RM_model,
  newdata = model_data, transform = TRUE)

sum1<-prediction_summary(y = model_data$ChinaVirusInterest,
  yrep = pred_1)
```


```{r}
#Normal Regression
set.seed(454)
pred_2 <- posterior_predict(
  NR_model,
  newdata = model_data, transform = TRUE)

sum2<-prediction_summary(y = model_data$ChinaVirusInterest,
  yrep = pred_2)
```

```{r}
#Repeated Measures + Normal Regression
set.seed(454)
pred_3 <- posterior_predict(
  model_2,
  newdata = model_data, transform = TRUE)

sum3<-prediction_summary(y = model_data$ChinaVirusInterest,
  yrep = pred_3)
```

```{r}
#Longitudinal Model
set.seed(454)
pred_4 <- posterior_predict(
  complexmod,
  newdata = model_data, transform = TRUE)

sum4<-prediction_summary(y = model_data$ChinaVirusInterest,
  yrep = pred_4)
```

```{r}
all_summ<-rbind(sum1,sum2,sum3,sum4)
rownames(all_summ)<- c("Model 1","Model 2","Model 3","Model 4")
all_summ
```

\
\



# 5. Results (Will)

## 5.1 Posterior Predctions All States 

### 5.1.a Table 

## 5.2 Posterior Prediction One State

## 5.3 Final Model 


\
\


# 6.Conclusion 

## 6.1 Limitations

## 6.2 Future Work

\
\


# 7. Acknowledgments and References 













